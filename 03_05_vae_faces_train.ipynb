{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run params\n",
    "section = 'vae'\n",
    "run_id = '0001'\n",
    "data_name = 'faces'\n",
    "RUN_FOLDER = 'run/{}/'.format(section)\n",
    "RUN_FOLDER += '_'.join([run_id, data_name])\n",
    "\n",
    "if not os.path.exists(RUN_FOLDER):\n",
    "    os.mkdir(RUN_FOLDER)\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'viz'))\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'images'))\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'weights'))\n",
    "\n",
    "mode =  'build' #'load' #\n",
    "\n",
    "\n",
    "DATA_FOLDER = './data/celeb/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 10\n",
    "BATCH_SIZE = 32\n",
    "transform = transforms.Compose([   \n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "filenames = np.array(glob(os.path.join(DATA_FOLDER, '*/*.jpg')))\n",
    "NUM_IMAGES = len(filenames)\n",
    "\n",
    "\n",
    "class SimpleDataset(Dataset):\n",
    "    def __init__(self, filenames, transform):\n",
    "        self.filenames = filenames\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.filenames[idx])\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SimpleDataset(filenames, transform)\n",
    "dataloader = DataLoader(dataset, BATCH_SIZE)\n",
    "z_dim = 200\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 128, 128])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dataloader)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, 2)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.dropout1 = nn.Dropout()\n",
    "\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 2)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.dropout2 = nn.Dropout()\n",
    "\n",
    "        self.conv3 = nn.Conv2d(64, 64, 3, 2)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.dropout3 = nn.Dropout()\n",
    "\n",
    "        self.conv4 = nn.Conv2d(64, 64, 3, 2)\n",
    "        self.bn4 = nn.BatchNorm2d(64)\n",
    "        self.dropout4 = nn.Dropout()\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.mu = nn.Linear(4096, z_dim)\n",
    "\n",
    "        self.log_var = nn.Linear(4096, z_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.pad(self.conv1(x), (1,0,1,0))\n",
    "        x = self.bn1(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        x = F.pad(self.conv2(x), (1,0,1,0))\n",
    "        x = self.bn2(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        x = F.pad(self.conv3(x), (1,0,1,0))\n",
    "        x = self.bn3(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = self.dropout3(x)\n",
    "\n",
    "        x = F.pad(self.conv4(x), (1,0,1,0))\n",
    "        x = self.bn4(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = self.dropout4(x)\n",
    "\n",
    "        x = self.flatten(x)\n",
    "\n",
    "        mu, log_var = self.mu(x), self.log_var(x)\n",
    "\n",
    "        def sampling(args):\n",
    "            mu, log_var = args\n",
    "            epsilon = torch.normal(0., 1., size=mu.shape).to(device)\n",
    "            return mu + torch.exp(log_var / 2) * epsilon\n",
    "\n",
    "        x = sampling([mu, log_var])\n",
    "\n",
    "        return x, mu, log_var\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-5.1759e-01,  2.3929e+00,  1.3602e+00,  2.7202e+00,  2.4660e+00,\n",
       "           1.3402e+00,  1.4359e+00,  4.8709e-01,  1.8287e-01,  1.0801e+00,\n",
       "           9.8907e-01, -4.2054e-01, -1.3979e-01,  2.9253e-01,  4.7928e-01,\n",
       "          -4.0135e-01, -2.7017e+00,  2.9082e-01, -6.1216e-01,  4.1141e-01,\n",
       "          -1.9953e-01, -2.1355e-01,  2.1881e+00,  4.2528e+00,  1.4462e+00,\n",
       "           1.5811e-01, -1.2270e+00,  6.7239e-01,  4.5569e-01, -8.3518e-01,\n",
       "           7.1327e-01,  1.5285e+00, -1.3974e-01,  2.0771e-01,  2.5645e+00,\n",
       "           5.4974e-01, -1.7486e+00,  1.7022e+00,  2.2719e+00, -2.6096e+00,\n",
       "          -8.7677e-01,  7.9289e-01,  7.6394e-01,  2.8425e-01,  2.2144e-01,\n",
       "           1.6229e+00, -2.1539e+00,  3.5489e-01, -4.8027e-01,  4.2101e-02,\n",
       "          -6.0902e-01, -2.4413e+00,  5.6538e-01,  1.1811e+00,  8.5354e-01,\n",
       "           6.5099e-01, -7.3052e-01, -1.7747e-02,  1.7858e-02, -1.1516e+00,\n",
       "           1.0280e+00, -1.0589e+00, -2.4579e-01, -1.2576e+00, -1.3307e+00,\n",
       "           8.2519e-01,  2.1257e-01, -2.9392e-01,  4.4002e-01,  7.1013e-01,\n",
       "           1.8916e+00, -2.0716e-01,  6.7705e-01,  9.7860e-02,  1.4519e+00,\n",
       "           6.2929e-02, -1.4108e+00, -6.5423e-01,  2.8032e+00, -1.4773e+00,\n",
       "          -1.2139e+00, -3.2136e-01, -1.1974e+00,  2.0433e-01, -1.6070e+00,\n",
       "           1.1021e+00,  3.1591e-01,  7.0080e-01, -1.2177e-01,  4.5703e-01,\n",
       "          -8.2752e-01,  1.0267e-02,  9.5035e-01, -1.1303e+00, -2.4152e-01,\n",
       "           6.0825e-01, -2.2454e-01,  1.4949e+00,  7.1731e-01, -7.6471e-01,\n",
       "           2.6348e+00,  3.0462e-01, -3.2374e-01, -5.6926e-01,  1.3971e-01,\n",
       "          -2.5425e-01,  1.0462e+00, -1.2942e+00,  1.3420e-01,  1.4208e+00,\n",
       "          -3.2812e-01, -7.6604e-01, -1.3371e+00,  1.7177e+00, -3.1623e-01,\n",
       "           6.2123e-01,  1.3828e+00, -2.3086e+00, -4.6966e-01,  1.0349e+00,\n",
       "          -3.3603e-01,  3.1083e-01,  4.6831e-01,  1.0961e-01, -2.1209e+00,\n",
       "           1.8526e-01,  1.2264e+00, -1.0435e-01, -1.0927e+00,  5.0847e-01,\n",
       "           1.4955e-01,  6.4810e-02,  1.1182e+00, -1.4423e+00, -1.4995e+00,\n",
       "           1.6032e-01,  1.8551e+00,  7.8767e-01, -2.7232e-01, -1.9815e-01,\n",
       "          -2.8209e+00,  1.0004e+00, -3.9960e-01, -9.4604e-01, -1.7408e+00,\n",
       "          -2.4325e-01,  4.1207e-01,  6.4390e-02, -5.1532e-01, -2.3206e-01,\n",
       "          -1.2666e+00, -8.5583e-01,  8.2701e-01,  7.4755e-02, -2.7512e+00,\n",
       "           1.4356e+00, -9.0399e-01, -3.2882e-01, -3.1005e-01,  1.5643e+00,\n",
       "          -2.5363e+00,  8.4699e-01, -3.2824e-03,  1.9383e+00, -6.8867e-01,\n",
       "           8.2225e-01, -1.1794e+00, -3.7495e-01, -4.2285e-01, -5.7665e-01,\n",
       "          -1.2232e+00,  5.3263e-01, -2.9348e-01,  4.3083e-01, -5.3199e-01,\n",
       "           5.5240e-01, -7.9102e-01,  1.5317e+00,  1.1904e+00,  3.0160e+00,\n",
       "          -8.7459e-01,  3.1349e-01, -4.2195e-01, -3.1177e-03, -4.8580e-02,\n",
       "          -5.1400e-01, -5.9244e-01,  4.2946e-01, -4.4461e-01, -1.2785e+00,\n",
       "           5.0370e-01, -2.9138e-01,  4.3609e-01,  1.0097e+00,  7.1846e-01,\n",
       "           1.3538e+00, -2.6366e-01, -9.1072e-01, -1.3856e+00,  2.5215e-01]],\n",
       "        device='cuda:0', grad_fn=<AddBackward0>),\n",
       " tensor([[-0.3440,  1.1407,  0.1878,  0.2811,  0.4929, -0.3890,  0.2790, -0.1188,\n",
       "           0.4768,  1.6060, -0.1200, -0.3906, -0.3107,  0.0905, -0.7151,  0.2661,\n",
       "           0.2957, -0.0582, -0.3931, -0.2243,  0.9978, -0.2184,  0.3964, -0.2461,\n",
       "          -0.2300, -0.6443, -0.6940, -0.1312,  1.2099, -0.0282,  0.0931,  0.9959,\n",
       "          -0.2226, -0.6530, -0.1020, -0.0759, -0.3900, -0.2377,  0.5067,  0.1938,\n",
       "          -0.4241,  0.0253, -0.5527, -0.4694, -0.9407,  0.0449,  0.6215,  0.1767,\n",
       "          -0.0563, -0.6032, -0.9167, -0.4221,  0.5346, -0.1786, -0.1900,  0.1783,\n",
       "           1.7066,  0.2357,  0.2981,  0.1044,  0.5969, -0.2689,  0.2269,  0.2928,\n",
       "          -0.4359,  0.7328,  0.4132, -0.1844,  0.0880, -0.0602,  0.8074,  0.0485,\n",
       "           0.5450, -0.6967,  0.7504,  0.3546, -0.9758, -0.8655,  0.5955, -0.0762,\n",
       "          -0.6865,  0.0380, -1.1642, -0.0197,  0.1060,  0.7399, -0.1262,  0.9009,\n",
       "          -0.0657,  0.7298, -0.4554, -0.0706,  0.7922,  0.7000, -1.3437,  0.1555,\n",
       "          -0.7104, -0.3593,  0.6895, -0.3978,  1.2428, -0.6731,  1.0092, -0.1987,\n",
       "          -0.0601,  0.1228,  0.0349, -0.1476,  0.6355,  1.3166, -0.2301, -0.7337,\n",
       "          -0.9695,  0.3472,  0.7704,  0.1354,  0.2903, -0.8001, -0.5057, -0.3041,\n",
       "           0.1009, -0.0975, -0.2076,  0.4035, -0.3423,  1.1438, -0.0465, -0.6142,\n",
       "          -0.0215,  0.5302, -0.4293, -0.0080, -0.4864,  0.0017, -0.3979,  1.0107,\n",
       "           1.5275,  0.2195, -0.3881, -0.1688, -0.9868, -0.4119,  0.6596,  0.5642,\n",
       "          -0.9359,  0.1913, -0.8391, -0.1814, -0.0239, -1.1127, -0.3375,  0.8320,\n",
       "          -0.0526,  0.0164, -1.4210, -0.4831, -0.2449, -0.6790,  0.6967,  0.0742,\n",
       "          -0.4957, -0.4236, -0.1143,  1.1173,  0.4027,  0.7696, -1.0935,  0.1570,\n",
       "           0.2370, -0.1566, -0.7691, -0.1157,  0.6503, -0.1230, -0.7496, -0.2098,\n",
       "          -0.4995,  1.0648,  0.2821,  0.9528, -0.6800,  0.0209, -0.1695, -1.0121,\n",
       "           0.1542, -0.4687, -0.7606,  0.6809, -0.7375, -0.5408,  0.8347, -0.6028,\n",
       "           0.2271,  0.7582,  0.1212, -0.0579,  0.5292, -0.3906, -0.4241,  0.6177]],\n",
       "        device='cuda:0', grad_fn=<AddmmBackward0>),\n",
       " tensor([[-3.3368e-01,  7.2207e-01, -2.3980e-01,  4.0218e-01,  3.7708e-01,\n",
       "           7.1539e-01,  5.8900e-01,  5.7842e-01, -3.3529e-01, -5.9129e-01,\n",
       "          -1.0117e-01, -2.2596e-04, -3.3738e-01,  8.4008e-02, -2.8075e-01,\n",
       "          -9.4471e-01,  5.9197e-01, -5.2046e-01, -1.0688e-01, -7.6272e-01,\n",
       "          -5.4999e-02, -1.1588e+00,  2.8407e-01,  1.1335e+00,  4.1811e-01,\n",
       "           2.0282e-01, -1.2439e-01, -6.7075e-01, -3.2349e-01, -2.5895e-01,\n",
       "           4.6683e-01,  6.0114e-02, -7.6073e-01, -1.0301e-01,  1.1379e-01,\n",
       "           7.2164e-02, -2.8343e-01, -4.8393e-01,  6.4522e-01,  8.7825e-01,\n",
       "           7.1576e-01,  4.9387e-01,  4.4808e-01,  1.6636e-01,  6.7150e-01,\n",
       "          -4.4451e-01,  2.0727e-01, -5.2522e-01,  6.3368e-01, -3.8698e-01,\n",
       "          -3.0265e-01,  5.0843e-01,  5.6206e-01,  5.6862e-01, -6.3541e-01,\n",
       "           9.5494e-02, -6.7053e-02, -2.4142e-01, -3.5899e-01,  4.2020e-01,\n",
       "          -2.7994e-01, -1.6846e-01, -7.8911e-01,  6.9802e-01,  6.7836e-01,\n",
       "          -3.7144e-01, -4.2643e-01, -6.3810e-02, -6.1344e-01, -8.3982e-01,\n",
       "          -2.1913e-01, -9.9566e-01, -2.1061e-01, -1.3081e-02, -1.8353e-01,\n",
       "           3.4949e-01, -3.8273e-01, -2.9404e-01,  8.2067e-01,  3.3522e-01,\n",
       "           3.7548e-01,  4.5286e-01, -3.1656e-01,  4.6322e-01, -6.8024e-01,\n",
       "           2.0065e-01, -1.4843e+00,  6.2272e-01, -6.6718e-01,  3.1026e-01,\n",
       "           4.1739e-01, -1.0025e+00, -4.1532e-01,  7.0679e-01, -3.2858e-03,\n",
       "          -2.5946e-01,  3.6497e-01,  5.0577e-01, -2.7478e-01, -6.7010e-01,\n",
       "           5.2293e-01,  6.5825e-01,  5.5013e-02,  2.9117e-01, -5.9648e-01,\n",
       "          -3.5224e-01, -1.4136e-01,  1.1763e-01,  4.7324e-01, -9.2300e-01,\n",
       "           6.9823e-01, -5.4065e-01, -5.9465e-01,  7.2967e-01,  3.9750e-01,\n",
       "          -2.3837e-01,  1.3845e-01,  3.9639e-01, -4.2289e-01,  3.6229e-03,\n",
       "           4.4573e-01, -2.3197e-01,  1.7664e-01, -5.4808e-01,  5.9694e-01,\n",
       "           5.7607e-02, -1.9977e-01,  1.1773e+00,  1.0086e+00, -6.6508e-01,\n",
       "           1.4471e-01, -1.1683e+00, -5.8507e-02, -2.0765e-01, -7.0261e-01,\n",
       "           5.0289e-02,  1.6469e-02, -7.9324e-01,  2.0852e-01, -5.0192e-02,\n",
       "           1.6429e+00, -1.5709e-01,  1.6661e-01, -1.5202e-01, -4.8389e-01,\n",
       "          -8.7456e-02,  7.3459e-01, -6.6637e-01, -6.3020e-01, -3.3196e-01,\n",
       "           7.3885e-02, -4.0099e-01, -2.6665e-01, -8.9842e-01,  3.6047e-01,\n",
       "           1.7133e-01,  1.7850e-01, -9.1410e-01, -3.4844e-01,  1.0146e+00,\n",
       "          -6.6732e-01,  5.9528e-01, -5.8024e-01, -6.5110e-01,  1.3540e-01,\n",
       "          -5.7030e-02, -1.0775e+00, -6.8021e-01, -4.0828e-01, -9.0644e-02,\n",
       "          -7.3468e-01, -8.1239e-02,  1.4437e-01, -1.2801e+00,  7.2609e-01,\n",
       "           9.3712e-02, -3.2450e-01, -8.0769e-01,  7.4090e-01, -2.4641e-01,\n",
       "           1.3844e+00, -1.3177e+00, -1.2540e-02,  1.9592e-02, -3.5943e-02,\n",
       "          -4.7918e-01, -2.6537e-01, -3.5589e-01,  2.0481e-01, -8.2591e-02,\n",
       "          -2.6847e-01,  2.9146e-01,  5.4886e-01, -3.7269e-02, -5.0137e-01,\n",
       "          -4.8560e-01,  2.6993e-01,  7.3647e-01, -9.0796e-01, -1.2428e+00]],\n",
       "        device='cuda:0', grad_fn=<AddmmBackward0>))"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Encoder().to(device)(torch.randn((1, 3, 128, 128)).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(z_dim, 64*6*6)\n",
    "\n",
    "        self.convT1 = nn.ConvTranspose2d(64, 64, 3, 2, 1)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.dropout1 = nn.Dropout()\n",
    "\n",
    "        self.convT2 = nn.ConvTranspose2d(64, 64, 3, 2, 1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.dropout2 = nn.Dropout()\n",
    "\n",
    "        self.convT3 = nn.ConvTranspose2d(64, 32, 3, 2, 1)\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "        self.dropout3 = nn.Dropout()\n",
    "\n",
    "        self.convT4 = nn.ConvTranspose2d(32, 3, 3, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = x.reshape(-1, 64, 6, 6)\n",
    "\n",
    "        x = F.pad(self.convT1(x), (2,1,2,1))      \n",
    "        x = self.bn1(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        x = F.pad(self.convT2(x), (2,1,2,1))      \n",
    "        x = self.bn2(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        x = F.pad(self.convT3(x), (2,1,2,1))      \n",
    "        x = self.bn3(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = self.dropout3(x)\n",
    "\n",
    "        x = F.pad(self.convT4(x), (2,1,2,1)) \n",
    "        \n",
    "        return torch.sigmoid(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 128, 128])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Decoder().to(device)(torch.randn((1, 200)).to(device)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder().to(device)\n",
    "        self.decoder = Decoder().to(device)\n",
    "    def forward(self, x):\n",
    "        t, mu, log_var = self.encoder(x)\n",
    "        x = self.decoder(t)\n",
    "        return x, t, mu, log_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AutoEncoder(\n",
       "  (encoder): Encoder(\n",
       "    (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2))\n",
       "    (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (dropout1): Dropout(p=0.5, inplace=False)\n",
       "    (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2))\n",
       "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (dropout2): Dropout(p=0.5, inplace=False)\n",
       "    (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2))\n",
       "    (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (dropout3): Dropout(p=0.5, inplace=False)\n",
       "    (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2))\n",
       "    (bn4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (dropout4): Dropout(p=0.5, inplace=False)\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    (mu): Linear(in_features=4096, out_features=200, bias=True)\n",
       "    (log_var): Linear(in_features=4096, out_features=200, bias=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (linear1): Linear(in_features=200, out_features=2304, bias=True)\n",
       "    (convT1): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (dropout1): Dropout(p=0.5, inplace=False)\n",
       "    (convT2): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (dropout2): Dropout(p=0.5, inplace=False)\n",
       "    (convT3): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (dropout3): Dropout(p=0.5, inplace=False)\n",
       "    (convT4): ConvTranspose2d(32, 3, kernel_size=(3, 3), stride=(2, 2))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model =AutoEncoder().to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_LOSS_FACTOR = 10000\n",
    "\n",
    "def kl_loss(mu, log_var):\n",
    "    kl_loss =  -0.5 * torch.sum(1 + log_var - torch.square(mu) - torch.exp(log_var))\n",
    "    return kl_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(200):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, inputs in enumerate(dataloader, 0):\n",
    "        \n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs = inputs.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs, _, mu, log_var = model(inputs)\n",
    "        loss = criterion(outputs, inputs) \n",
    "\n",
    "        loss += kl_loss(mu, log_var)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "    print(f'[{epoch + 1}] loss: {running_loss / len(dataloader):.3f}')\n",
    "    torch.save(model, RUN_FOLDER + \"/weights/weight.pt\")\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "726535c0f6f932cb5fb7f4ccf074a920e012d87bcb619fd5c2bde3239c103324"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
