{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run params\n",
    "section = 'vae'\n",
    "run_id = '0001'\n",
    "data_name = 'faces'\n",
    "RUN_FOLDER = 'run/{}/'.format(section)\n",
    "RUN_FOLDER += '_'.join([run_id, data_name])\n",
    "\n",
    "if not os.path.exists(RUN_FOLDER):\n",
    "    os.mkdir(RUN_FOLDER)\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'viz'))\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'images'))\n",
    "    os.mkdir(os.path.join(RUN_FOLDER, 'weights'))\n",
    "\n",
    "mode =  'build' #'load' #\n",
    "\n",
    "\n",
    "DATA_FOLDER = './data/celeb/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 10\n",
    "BATCH_SIZE = 32\n",
    "transform = transforms.Compose([   \n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "filenames = np.array(glob(os.path.join(DATA_FOLDER, '*/*.jpg')))\n",
    "NUM_IMAGES = len(filenames)\n",
    "\n",
    "\n",
    "class SimpleDataset(Dataset):\n",
    "    def __init__(self, filenames, transform):\n",
    "        self.filenames = filenames\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.filenames[idx])\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SimpleDataset(filenames, transform)\n",
    "dataloader = DataLoader(dataset, BATCH_SIZE)\n",
    "z_dim = 200\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 128, 128])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dataloader)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, 2)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.dropout1 = nn.Dropout()\n",
    "\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 2)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.dropout2 = nn.Dropout()\n",
    "\n",
    "        self.conv3 = nn.Conv2d(64, 64, 3, 2)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.dropout3 = nn.Dropout()\n",
    "\n",
    "        self.conv4 = nn.Conv2d(64, 64, 3, 2)\n",
    "        self.bn4 = nn.BatchNorm2d(64)\n",
    "        self.dropout4 = nn.Dropout()\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.mu = nn.Linear(4096, z_dim)\n",
    "\n",
    "        self.log_var = nn.Linear(4096, z_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.pad(self.conv1(x), (1,0,1,0))\n",
    "        x = self.bn1(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        x = F.pad(self.conv2(x), (1,0,1,0))\n",
    "        x = self.bn2(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        x = F.pad(self.conv3(x), (1,0,1,0))\n",
    "        x = self.bn3(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = self.dropout3(x)\n",
    "\n",
    "        x = F.pad(self.conv4(x), (1,0,1,0))\n",
    "        x = self.bn4(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = self.dropout4(x)\n",
    "\n",
    "        x = self.flatten(x)\n",
    "\n",
    "        mu, log_var = self.mu(x), self.log_var(x)\n",
    "\n",
    "        def sampling(args):\n",
    "            mu, log_var = args\n",
    "            epsilon = torch.normal(0., 1., size=mu.shape).to(device)\n",
    "            return mu + torch.exp(log_var / 2) * epsilon\n",
    "\n",
    "        x = sampling([mu, log_var])\n",
    "\n",
    "        return x, mu, log_var\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-6.9292e-02, -1.7313e+00, -2.4216e+00,  1.8383e+00,  3.3043e-03,\n",
       "           6.6487e-03,  6.0011e-01,  1.1177e-01, -2.5705e-01,  4.3092e-01,\n",
       "          -2.8566e+00,  5.2822e-01, -1.2150e+00, -2.3023e+00, -5.6485e-02,\n",
       "           1.3575e+00,  9.9283e-01, -4.7911e-02,  1.3520e+00,  5.8625e-02,\n",
       "           6.8887e-01, -3.6084e-02, -2.9957e-01,  1.1842e+00,  5.5238e-01,\n",
       "           4.6386e-01,  9.4920e-01, -5.2600e-01,  2.4729e+00,  4.4372e-01,\n",
       "           1.0076e+00, -1.6362e-01, -2.3901e-01, -5.4897e-01,  1.1118e-01,\n",
       "          -1.5194e+00, -1.2079e-01,  3.3674e-01,  5.8869e-01,  1.2844e+00,\n",
       "          -1.5311e+00,  1.2524e+00, -3.6729e+00,  1.1425e+00, -1.5921e+00,\n",
       "           5.8042e-01,  9.4766e-01,  9.1553e-01,  1.9330e+00, -3.5187e+00,\n",
       "          -1.0907e+00, -1.5125e+00,  2.3162e+00, -1.4165e+00, -9.0981e-01,\n",
       "           1.5136e+00, -7.3439e-01, -1.9492e-01, -3.8977e+00, -7.9682e-01,\n",
       "          -1.0914e+00, -5.5134e-01,  1.7630e+00,  2.3743e-01, -8.0812e-02,\n",
       "           2.7078e+00, -5.8059e-01, -3.3328e-01, -1.1388e+00, -1.2279e+00,\n",
       "          -3.1990e+00, -3.9462e-01,  5.7609e-01, -2.6452e+00,  7.3889e-01,\n",
       "          -1.3307e-02,  5.4205e-02,  1.4200e+00,  1.3029e+00, -1.1568e+00,\n",
       "           6.0342e-02,  6.3095e-02, -1.8771e+00, -3.0769e-01, -3.5082e-01,\n",
       "           8.1552e-02,  4.1394e-01, -6.6438e-01, -3.5934e-01, -2.7845e-01,\n",
       "          -9.8361e-01,  3.1004e+00,  8.4163e-01,  6.5095e-01,  1.5281e+00,\n",
       "           2.9166e+00,  8.5596e-01, -9.6906e-01, -8.4392e-01, -1.0478e+00,\n",
       "           1.0823e+00,  1.5037e+00, -1.4575e+00,  7.9489e-01, -2.2569e-01,\n",
       "          -8.7960e-01,  9.3712e-02,  1.1153e+00, -6.2541e-01, -7.1634e-01,\n",
       "           1.2461e+00, -2.2455e+00,  8.4467e-01,  1.0614e+00, -6.4566e-01,\n",
       "          -1.4999e+00, -6.5874e-01,  1.0610e+00,  5.4949e-02,  2.2131e+00,\n",
       "          -1.4087e+00,  1.1265e+00, -4.8388e-01, -3.4320e-02,  9.3498e-01,\n",
       "           1.0757e+00, -3.2101e-01,  1.1280e-01, -7.3991e-01, -1.1702e+00,\n",
       "          -8.4805e-01, -7.0360e-01, -4.1267e-01, -1.5426e+00, -1.7071e+00,\n",
       "          -3.0983e-01,  1.7160e-01,  2.5179e+00,  1.8206e+00,  9.5731e-01,\n",
       "          -5.5635e-02,  2.7656e+00, -8.1705e-01, -4.1284e+00,  3.1652e+00,\n",
       "          -1.6649e-01,  1.1678e+00, -3.8109e-02,  1.0191e+00, -8.8739e-01,\n",
       "           4.1187e-01, -2.1983e+00,  1.0393e+00, -4.3789e-01, -2.2353e-01,\n",
       "          -2.1588e-01, -7.3980e-01, -5.2982e-01,  5.5533e-01, -4.3836e-01,\n",
       "          -4.4361e-01, -1.2469e+00,  1.0146e-01,  1.5428e+00, -1.6677e-01,\n",
       "          -1.6549e+00,  4.8747e-01, -8.6231e-02, -9.0891e-01,  1.6358e+00,\n",
       "           6.4461e-01,  3.5215e-01,  1.1238e+00, -1.0388e+00,  1.7426e+00,\n",
       "           1.4384e+00, -9.8507e-02, -3.5464e-01, -2.9227e-01, -1.2148e+00,\n",
       "          -8.5040e-02,  3.7325e-01, -9.7459e-01, -1.6304e-01,  4.5635e-01,\n",
       "           3.6871e-01,  3.3333e-01,  1.6808e+00, -1.1963e+00, -2.5295e+00,\n",
       "           9.4810e-01,  1.6078e+00, -1.4987e+00,  3.8145e-01,  7.9541e-01,\n",
       "           1.0777e+00,  2.1750e+00,  3.5875e-01, -1.1772e+00,  1.7125e+00]],\n",
       "        device='cuda:0', grad_fn=<AddBackward0>),\n",
       " tensor([[-1.9631e-01, -2.0717e-01, -9.6378e-01,  1.0917e+00, -2.0658e-02,\n",
       "           1.0201e+00, -7.7841e-01, -4.3937e-01, -3.7886e-01,  1.1779e-01,\n",
       "          -1.5841e+00,  2.3061e-01, -3.1662e-01, -9.2196e-01, -3.6331e-02,\n",
       "           2.6922e-01,  8.4628e-02, -1.4335e-01,  8.8302e-01, -5.0395e-01,\n",
       "           3.6472e-01, -3.6488e-01,  5.0569e-02,  4.3870e-01,  3.7942e-01,\n",
       "          -1.0400e+00,  2.7352e-01, -4.5200e-01,  1.0648e+00,  1.3737e-02,\n",
       "           2.6884e-01, -4.3003e-01, -4.2302e-01, -7.7782e-01,  5.9721e-01,\n",
       "           2.9863e-01, -5.9255e-01, -6.6918e-02,  3.7753e-01, -6.1902e-02,\n",
       "          -5.9638e-01,  8.3882e-01, -7.0710e-01, -1.1960e-01, -1.2008e+00,\n",
       "           6.2068e-02,  1.2981e+00,  1.3051e+00, -2.4343e-01, -1.4333e+00,\n",
       "          -1.1018e+00, -6.6324e-01,  6.9055e-01, -5.1412e-01, -3.5343e-01,\n",
       "           1.1581e-01, -3.0468e-01, -6.0656e-01, -4.0024e-01,  4.3831e-01,\n",
       "          -1.0642e-01, -4.3697e-01,  6.9488e-01, -2.5573e-02, -4.8957e-01,\n",
       "           5.8036e-01, -8.6851e-01,  4.8900e-01, -1.3139e+00, -1.1089e+00,\n",
       "          -1.5347e+00,  1.1531e-01, -8.3319e-02, -1.4390e-01,  4.1660e-01,\n",
       "          -4.6018e-01,  1.4063e-01, -3.1776e-01,  6.1312e-02, -3.6542e-01,\n",
       "          -6.8388e-02, -8.6070e-01, -7.3323e-01,  3.4712e-01, -2.2439e-01,\n",
       "          -4.0107e-01,  7.6837e-01, -3.7280e-01,  2.8312e-01,  4.5662e-01,\n",
       "           1.7100e-01,  5.7645e-01, -1.1020e-01,  3.7823e-01,  2.5737e-01,\n",
       "           1.1267e+00,  1.5023e+00,  4.5994e-01, -5.6017e-01, -3.4512e-01,\n",
       "           2.7942e-01,  1.0880e+00,  9.0879e-01, -1.2144e-01, -5.5297e-01,\n",
       "          -1.0556e+00,  4.3597e-02,  5.1869e-01, -6.3637e-01, -1.1049e+00,\n",
       "           2.7945e-01, -1.4187e+00, -2.0254e-01,  7.4088e-01,  2.3751e-01,\n",
       "          -3.1578e-01,  2.0208e-01,  5.1510e-01,  4.6222e-02,  5.4042e-01,\n",
       "          -8.5145e-01, -2.0171e-01, -3.3236e-01, -3.7220e-01,  6.6747e-01,\n",
       "           9.2008e-01,  1.5573e-01,  1.1145e-01,  7.3300e-01,  1.5280e-01,\n",
       "           2.9374e-01, -4.6763e-01, -8.0992e-02, -1.9324e-01, -4.4225e-01,\n",
       "           2.1578e-01, -6.8587e-01,  5.0310e-01,  5.7237e-01, -1.6526e-01,\n",
       "          -1.1104e-03,  1.4928e+00, -1.1036e-02, -7.9224e-01, -1.2706e+00,\n",
       "          -8.0094e-01,  1.4054e-01, -1.1382e-01,  9.0947e-02, -8.1663e-01,\n",
       "          -8.3238e-01,  9.2114e-02, -6.7664e-01,  8.9016e-02,  7.7111e-01,\n",
       "           1.8620e-01,  1.3448e-01, -3.8268e-01,  7.5888e-01, -7.1717e-01,\n",
       "          -2.4529e-01, -3.8752e-01, -2.1028e-01, -1.1421e-01, -3.5514e-01,\n",
       "          -1.5813e-01,  1.6827e-02, -4.0434e-01, -1.0702e+00,  6.6454e-01,\n",
       "           8.2639e-01, -4.0150e-01,  1.7638e-01, -4.7719e-01,  7.2434e-01,\n",
       "           7.0078e-01, -8.0100e-01, -2.4644e-01, -1.1305e-01,  3.1924e-01,\n",
       "           8.4616e-01,  1.0249e+00,  1.7015e-01, -8.1298e-01, -6.7555e-01,\n",
       "           1.7056e+00,  7.1392e-01,  8.2281e-01,  8.3159e-01, -7.0651e-01,\n",
       "          -2.0586e-01, -1.6756e-01,  7.3623e-01, -2.8213e-01, -9.8263e-04,\n",
       "           3.8390e-01,  4.5290e-01,  1.2405e-01, -1.3007e+00,  1.2360e+00]],\n",
       "        device='cuda:0', grad_fn=<AddmmBackward0>),\n",
       " tensor([[ 0.2921,  0.7751, -0.3167, -0.2455, -0.1015,  0.5841, -0.8286, -0.4639,\n",
       "           0.0514, -0.6523, -0.3338,  0.0612,  1.0345, -0.8039,  0.5079, -0.3817,\n",
       "          -0.2928, -0.6946, -0.8262, -0.3961,  0.1418, -0.3279, -0.6079,  0.3334,\n",
       "           0.6314,  0.3018,  0.0458, -0.5369,  0.5399, -0.7822,  0.1344, -1.0776,\n",
       "          -0.9061,  0.2128, -0.3183,  0.2309, -0.2717,  0.4262, -1.2197, -0.9101,\n",
       "           0.6153,  0.8164,  1.7829,  0.6229,  0.9274, -0.4305, -1.1501,  0.5800,\n",
       "           0.2706,  1.0173,  0.3952,  0.4456, -0.0457,  0.1286, -0.2115,  0.1450,\n",
       "          -0.4501,  0.1096,  0.5034,  0.1945, -0.4949, -0.5056, -0.4012,  0.5943,\n",
       "           0.3687,  0.3931, -0.2700, -0.2444, -0.4139,  0.3400, -0.2153,  0.5236,\n",
       "          -0.4141,  0.6408,  0.3274, -0.7237, -1.1248,  0.6396,  0.3788,  0.4612,\n",
       "           0.1505, -0.0248,  0.2741, -0.1852,  0.5203,  0.5173,  0.0423,  0.0256,\n",
       "          -0.4381,  0.1956,  0.2809,  0.8903, -0.7032,  0.5168, -0.2313,  0.0295,\n",
       "           0.1173, -0.2748,  0.2527,  0.8323, -1.0006,  0.5354,  0.5777,  0.6203,\n",
       "          -0.4492, -1.1305,  0.9376,  0.8674, -0.2601, -0.6480,  0.1998,  0.6281,\n",
       "           0.3842, -0.8924,  0.0505,  1.5210, -0.3763,  0.5839, -0.5771,  1.0088,\n",
       "           0.3071,  0.5642,  0.7695, -0.0874, -0.9211, -1.2519,  0.5451, -0.0519,\n",
       "           1.4199, -0.1831,  0.2575, -0.7192,  0.4427,  0.7312,  0.2952, -0.3177,\n",
       "          -0.3701,  0.7360,  0.1794, -0.5023, -0.2235,  0.3044, -0.3432,  0.7488,\n",
       "           0.8267, -0.9959,  0.0347,  0.2237,  0.3990,  0.3537,  0.2772,  0.4386,\n",
       "           0.5173,  0.2529,  0.4442,  0.1150,  0.3173, -1.1833, -0.2308,  0.6320,\n",
       "          -0.4461, -0.7457, -0.1481, -0.0745,  0.2483,  1.3643,  0.6843, -0.3080,\n",
       "           0.3498, -0.9376,  0.5774, -0.5051,  0.0328,  0.7546,  0.0729, -0.7159,\n",
       "          -0.2613, -0.7722,  0.5198, -0.4999, -0.4584,  0.5040,  0.4900, -0.5677,\n",
       "          -0.1276, -0.3072, -0.3720, -0.2355,  0.1736,  0.5316, -0.2515,  0.9527,\n",
       "           0.9416,  0.1138, -0.4312, -0.1047,  0.7791, -0.5251, -0.2355, -1.3561]],\n",
       "        device='cuda:0', grad_fn=<AddmmBackward0>))"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Encoder().to(device)(torch.randn((1, 3, 128, 128)).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(z_dim, 64*6*6)\n",
    "\n",
    "        self.convT1 = nn.ConvTranspose2d(64, 64, 3, 2, 1)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.dropout1 = nn.Dropout()\n",
    "\n",
    "        self.convT2 = nn.ConvTranspose2d(64, 64, 3, 2, 1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.dropout2 = nn.Dropout()\n",
    "\n",
    "        self.convT3 = nn.ConvTranspose2d(64, 32, 3, 2, 1)\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "        self.dropout3 = nn.Dropout()\n",
    "\n",
    "        self.convT4 = nn.ConvTranspose2d(32, 3, 3, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = x.reshape(-1, 64, 6, 6)\n",
    "\n",
    "        x = F.pad(self.convT1(x), (2,1,2,1))      \n",
    "        x = self.bn1(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        x = F.pad(self.convT2(x), (2,1,2,1))      \n",
    "        x = self.bn2(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        x = F.pad(self.convT3(x), (2,1,2,1))      \n",
    "        x = self.bn3(x)\n",
    "        x = F.leaky_relu(x)\n",
    "        x = self.dropout3(x)\n",
    "\n",
    "        x = F.pad(self.convT4(x), (2,1,2,1)) \n",
    "        \n",
    "        return torch.sigmoid(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 128, 128])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Decoder().to(device)(torch.randn((1, 200)).to(device)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder().to(device)\n",
    "        self.decoder = Decoder().to(device)\n",
    "    def forward(self, x):\n",
    "        t, mu, log_var = self.encoder(x)\n",
    "        x = self.decoder(t)\n",
    "        return x, t, mu, log_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AutoEncoder(\n",
       "  (encoder): Encoder(\n",
       "    (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2))\n",
       "    (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (dropout1): Dropout(p=0.5, inplace=False)\n",
       "    (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2))\n",
       "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (dropout2): Dropout(p=0.5, inplace=False)\n",
       "    (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2))\n",
       "    (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (dropout3): Dropout(p=0.5, inplace=False)\n",
       "    (conv4): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2))\n",
       "    (bn4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (dropout4): Dropout(p=0.5, inplace=False)\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "    (mu): Linear(in_features=4096, out_features=200, bias=True)\n",
       "    (log_var): Linear(in_features=4096, out_features=200, bias=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (linear1): Linear(in_features=200, out_features=2304, bias=True)\n",
       "    (convT1): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (dropout1): Dropout(p=0.5, inplace=False)\n",
       "    (convT2): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (dropout2): Dropout(p=0.5, inplace=False)\n",
       "    (convT3): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (dropout3): Dropout(p=0.5, inplace=False)\n",
       "    (convT4): ConvTranspose2d(32, 3, kernel_size=(3, 3), stride=(2, 2))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model =AutoEncoder().to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_LOSS_FACTOR = 10000\n",
    "\n",
    "def kl_loss(mu, log_var):\n",
    "    kl_loss =  -0.5 * torch.sum(1 + log_var - torch.square(mu) - torch.exp(log_var))\n",
    "    return kl_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] loss: 1738.996\n",
      "[2] loss: 1622.546\n",
      "[3] loss: 1596.606\n",
      "[4] loss: 1590.767\n",
      "[5] loss: 1589.142\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(200):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, inputs in enumerate(dataloader, 0):\n",
    "        \n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs = inputs.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs, _, mu, log_var = model(inputs)\n",
    "        loss = criterion(outputs, inputs) * R_LOSS_FACTOR\n",
    "\n",
    "        loss += kl_loss(mu, log_var)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "    print(f'[{epoch + 1}] loss: {running_loss / len(dataloader):.3f}')\n",
    "    torch.save(model, RUN_FOLDER + \"/weights/weight.pt\")\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "726535c0f6f932cb5fb7f4ccf074a920e012d87bcb619fd5c2bde3239c103324"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
